# download the data and install right dependenciesM
from google.colab import drive
drive.mount('/content/gdrive')
!mkdir celeba
!unzip /content/gdrive/My\ Drive/img_align_celeba.zip -d celeba

!pip uninstall torch
!pip uninstall torchvision
!pip install torch==1.4.0
!pip install torchvision==0.5.0


from __future__ import print_function
# %matplotlib inline
import argparse
import os
import random
import torch
import torch.nn as nn
from torch.distributions import Normal
import torch.nn.parallel
import torch.backends.cudnn as cudnn
import torch.optim as optim
import torch.utils.data
import torchvision.datasets as dset
import torchvision.transforms as transforms
import torchvision.utils as vutils
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.animation as animation
from IPython.display import HTML
from collections import deque
import copy
from tqdm import tqdm
# Set random seed for reproducibility
manualSeed = 999
# manualSeed = random.randint(1, 10000) # use if you want new results
print("Random Seed: ", manualSeed)
random.seed(manualSeed)
torch.manual_seed(manualSeed)


torch.autograd.set_detect_anomaly(True)  # For debugging

# Root directory for dataset
dataroot = "celeba"

# Number of workers for dataloader
workers = 4

# Batch size during training
batch_size = 128

# Spatial size of training images. All images will be resized to this
#   size using a transformer.
image_size = 64

# Number of channels in the training images. For color images this is 3
nc = 3

# Size of z latent vector (i.e. size of generator input)
nz = 100

# Size of feature maps in generator
ngf = 64

# Size of feature maps in discriminator
ndf = 64

# size of correlated/mediator codes
nmc = 2

# Number of training epochs
num_epochs = 250

# Learning rate for optimizers
lr = 0.0001

# learning rate for mediator optimizer
m_lr = 0.0005


# Beta1 hyperparam for Adam optimizers
beta1 = 0.5

# Number of GPUs available. Use 0 for CPU mode.
ngpu = 1

# Size of the queue of keeping previous parameters
K = 5

# Hard code numbers that get used in the mediator
LOG_SIG_MAX = 2
LOG_SIG_MIN = -20
EPSILON = 1e-6

# Create the dataset
dataset = dset.ImageFolder(root=dataroot,
                           transform=transforms.Compose([
                               transforms.Resize(image_size),
                               transforms.CenterCrop(image_size),
                               transforms.ToTensor(),
                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),
                           ]))
# Create the dataloader
dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,
                                         shuffle=True, num_workers=workers)

# Decide which device we want to run on
device = torch.device("cuda:0" if (torch.cuda.is_available() and ngpu > 0) else "cpu")

# Plot some training images
real_batch = next(iter(dataloader))
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=2, normalize=True).cpu(), (1, 2, 0)))


# custom weights initialization called on netG and netD
def weights_init(m):
    classname = m.__class__.__name__
    if classname.find('Conv') != -1:
        nn.init.normal_(m.weight.data, 0.0, 0.02)
    elif classname.find('BatchNorm') != -1:
        nn.init.normal_(m.weight.data, 1.0, 0.02)
        nn.init.constant_(m.bias.data, 0)


######################################################################
# # Mediates with correlated codes


class Mediator(nn.Module):
    '''
    Mediator/correlator intervenes with the learning dynamics
    '''
    def __init__(self,ngpu):
        super(Mediator, self).__init__()
        self.ngpu = ngpu
        self.main = nn.Sequential(
            # input is (nc) x 64 x 64
            nn.Conv2d(nc, 1, kernel_size=20, stride=5, bias=False)
        )

        self.concat = nn.Linear(81+nz, 128)

        self.embed_mean = nn.Linear(128, nmc)
        self.embed_log_std = nn.Linear(128, nmc)

        self.action_scale = torch.tensor(1)
        self.action_bias = torch.tensor(0.0)

    def forward(self, real_data, noise):
        x = self.main(real_data).view(batch_size,-1)
        x = self.concat(torch.cat((x, noise.view(-1, nz)), dim=1))
        mean, log_std = self.embed_mean(x), self.embed_log_std(x)
        log_std = torch.clamp(log_std, min=LOG_SIG_MIN, max=LOG_SIG_MAX)
        std = torch.exp(log_std)
        return mean, std

    def act(self, real_data, noise):
        '''
        pathwise derivative estimator for taking actions.
        :param x_player_action:
        :param y_player_action:
        :return:
        '''
        mean, std = self.forward(real_data, noise)
        normal = Normal(mean, std)
        x = normal.rsample()
        y = torch.tanh(x)
        action = y*self.action_scale + self.action_bias
        log_prob = normal.log_prob(action)
        # Enforcing Action Bound
        log_prob -= torch.log(self.action_scale * (1 - y.pow(2)) + EPSILON)
        log_prob = log_prob.sum(1, keepdim=True)
        mean = torch.tanh(mean) * self.action_scale + self.action_bias
        return action, log_prob, mean


######################################################################
# Generator
# ~~~~~~~~~
# Generator Code

class Generator(nn.Module):
    def __init__(self, ngpu):
        super(Generator, self).__init__()
        self.ngpu = ngpu
        self.main = nn.Sequential(
            # input is Z, going into a convolution
            nn.ConvTranspose2d(nz+nmc, ngf * 8, 4, 1, 0, bias=False),
            nn.BatchNorm2d(ngf * 8),
            nn.ReLU(True),
            # state size. (ngf*8) x 4 x 4
            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ngf * 4),
            nn.ReLU(True),
            # state size. (ngf*4) x 8 x 8
            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ngf * 2),
            nn.ReLU(True),
            # state size. (ngf*2) x 16 x 16
            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ngf),
            nn.ReLU(True),
            # state size. (ngf) x 32 x 32
            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),
            nn.Tanh()
            # state size. (nc) x 64 x 64
        )

    def forward(self, input):
        return self.main(input)

######################################################################
# We instantiate the mediator and apply the ``weights_init``
# function. Check out the printed model to see how the mediator object is
# structured.
#
# Create the Mediator


netM = Mediator(ngpu).to(device)

# Handle multi-gpu if desired
if (device.type == 'cuda') and (ngpu > 1):
    netM = nn.DataParallel(netM, list(range(ngpu)))

# Apply the weights_init function to randomly initialize all weights
#  to mean=0, stdev=0.2.
netM.apply(weights_init)

# Print the model
print(netM)

######################################################################
# Now, we can instantiate the generator and apply the ``weights_init``
# function. Check out the printed model to see how the generator object is
# structured.
#

# Create the generator
netG = Generator(ngpu).to(device)

# Handle multi-gpu if desired
if (device.type == 'cuda') and (ngpu > 1):
    netG = nn.DataParallel(netG, list(range(ngpu)))

# Apply the weights_init function to randomly initialize all weights
#  to mean=0, stdev=0.2.
netG.apply(weights_init)

# Print the model
print(netG)


######################################################################
# Discriminator
# ~~~~~~~~~~~~~
########################################################################
# Discriminator Code

class Discriminator(nn.Module):
    def __init__(self, ngpu):
        super(Discriminator, self).__init__()
        self.ngpu = ngpu
        self.main = nn.Sequential(
            # input is (nc) x 64 x 64
            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),
            nn.LeakyReLU(0.2, inplace=True),
            # state size. (ndf) x 32 x 32
            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ndf * 2),
            nn.LeakyReLU(0.2, inplace=True),
            # state size. (ndf*2) x 16 x 16
            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ndf * 4),
            nn.LeakyReLU(0.2, inplace=True),
            # state size. (ndf*4) x 8 x 8
            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ndf * 8),
            nn.LeakyReLU(0.2, inplace=True),
            # state size. (ndf*8) x 4 x 4
            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False)
        )
        self.fn = nn.Linear(nmc+1, 1)

    def forward(self, input, codes):
        x = self.main(input)
        codes = torch.reshape(codes, (batch_size, -1, 1, 1))
        x = torch.cat([x, codes], dim=1).view(batch_size, -1)
        x = self.fn(x)
        x = torch.sigmoid(x)
        return x


######################################################################
# Now, as with the generator, we can create the discriminator, apply the
# ``weights_init`` function, and print the model’s structure.
#

# Create the Discriminator
netD = Discriminator(ngpu).to(device)

# Handle multi-gpu if desired
if (device.type == 'cuda') and (ngpu > 1):
    netD = nn.DataParallel(netD, list(range(ngpu)))

# Apply the weights_init function to randomly initialize all weights
#  to mean=0, stdev=0.2.
netD.apply(weights_init)

# Print the model
print(netD)


# Initialize BCELoss function
criterion = nn.BCELoss()

# Create batch of latent vectors that we will use to visualize
#  the progression of the generator
fixed_noise = torch.randn(64, nz, 1, 1, device=device)

# fixed mediator codes that we will use to visualize the progress of the generator.
# For the beginning we set them it to zero
fixed_codes = torch.zeros(64, nmc, 1, 1, device= device)

# Establish convention for real and fake labels during training
real_label = 1
fake_label = 0

# Setup Adam optimizers for G, D and M
optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))
optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))
optimizerM = optim.Adam(netM.parameters(), lr=m_lr, betas=(beta1, 0.999))

######################################################################
# Training
# ~~~~~~~~
# Training Loop

# Lists to keep track of progress
img_list = []
G_losses = []
D_losses = []
iters = 0

# Queue of past strategies
G_queue = deque(maxlen=K)
G_queue.append(copy.deepcopy(netG.state_dict()))

D_queue = deque(maxlen=K)
D_queue.append(copy.deepcopy(netD.state_dict()))


print("Starting Training Loop...")
# For each epoch
for epoch in range(num_epochs):
    # For each batch in the dataloader
    for i, data in enumerate(dataloader, 0):

        if i>1500:
            break

        # Format batch
        real_cpu = data[0].to(device)
        b_size = real_cpu.size(0)
        real_labels = torch.full((b_size,), real_label, device=device)
        fake_labels = torch.full((b_size,), fake_label, device=device)

        ##### input to the G without code ########
        noise_without_code = torch.randn(b_size, nz, 1, 1, device=device)
        ############################
        # Mediator M proposes a code
        ###########################
        codes, log_prob, mean = netM.act(real_cpu,noise_without_code)
        #codes = mean.detach()
        codes = codes.detach()

        ############################
        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))
        ###########################
        ## Train with all-real batch
        netD.zero_grad()
        D_gains = []  # To store the computations needed for both FTL and mediator computations.
        # FTL Part Starts
        for param in D_queue:  # Note that D_x and D_G_z1 at the end are corresponding with the latest strategy.
            # Real part
            netD.load_state_dict(param)
            # Forward pass real batch through D
            real_output = netD(real_cpu, codes)
            D_x = real_output.mean().item()

            # Fake part
            # Generate batch of latent vectors
            noise = torch.cat([noise_without_code, codes.reshape(batch_size, nmc, 1, -1)], dim=1)
            # Generate fake image batch with G
            fake = netG(noise)
            # Classify all fake batch with D
            fake_output = netD(fake.detach(), codes)
            D_G_z1 = fake_output.mean().item()
            # Calculate D's loss on the all-fake batch and real batch
            D_gains.append(criterion(fake_output, fake_labels) + criterion(real_output, real_labels))

        # Calculate gradients for D in backward pass FTL style
        errD = sum(D_gains)/len(D_gains)
        errD.backward()
        # Update D
        optimizerD.step()
        # FTL ends
        # D_gains = [e.item() for e in D_gains]

        # adding the current parameter to the G_queue
        D_queue.append(copy.deepcopy(netD.state_dict()))

        ############################
        # (2) Update G network: maximize log(D(G(z)))
        ###########################
        netG.zero_grad()
        G_gains = []
        # Since we just updated D, perform another forward pass of all-fake batch through D
        for param in G_queue:
            netG.load_state_dict(param)
            fake = netG(noise)
            output = netD(fake, codes)
            # Calculate G's loss based on this output
            G_gains.append(criterion(output, real_labels))

        # Calculate gradients for G FTL style
        errG = sum(G_gains)/len(G_gains)
        errG.backward()
        D_G_z2 = output.mean().item()
        # Update G
        optimizerG.step()

        # G_gains = [e.item() for e in G_gains]

        # adding the current parameter to the G_queue
        G_queue.append(copy.deepcopy(netG.state_dict()))

        ############################
        # (3) Update M network using reward
        ###########################
        # mediator updates
        netM.zero_grad()
        # computing reward
        reward = torch.tensor(0.0)
        for k in range(len(G_gains)):
            for j in range(k + 1, len(G_gains)):
                reward -= np.power(G_gains[k].item() - G_gains[j].item(), 2)
                reward -= np.power(D_gains[k].item() - D_gains[j].item(), 2)
                # reward -= torch.relu(G_gains[k].mean() - G_gains[j].mean()).item()
                # reward -= torch.relu(D_gains[k].mean() - D_gains[j].mean()).item()

        reward = reward / (len(G_gains) * len(G_gains) / 4)

        mediator_loss = -(log_prob * reward).mean()
        mediator_loss.backward()
        optimizerM.step()
        # optimization done

        # Output training stats
        if i % 100 == 0:
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tLOSS_M: %.4f\tM_Reward: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, num_epochs, i, len(dataloader),
                     errD.item(), errG.item(), mediator_loss.item(),reward, D_x, D_G_z1, D_G_z2))

        # Save Losses for plotting later
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on fixed_noise
        if (iters % 1500 == 0) or ((epoch == num_epochs - 1) and (i == len(dataloader) - 1)):
            print("saving the models")
            torch.save(netG.state_dict(), 'netG.pt')
            torch.save(netM.state_dict(), 'netM.pt')
            with torch.no_grad():
                fake = netG(torch.cat([fixed_noise, fixed_codes], dim=1)).detach().cpu()
            img_list.append(vutils.make_grid(fake, padding=2, normalize=True))

        iters += 1

######################################################################
# Results
# -------

plt.figure(figsize=(10, 5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses, label="G")
plt.plot(D_losses, label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()

######################################################################
# **Visualization of G’s progression**

# %%capture
fig = plt.figure(figsize=(8, 8))
plt.axis("off")
ims = [[plt.imshow(np.transpose(i, (1, 2, 0)), animated=True)] for i in img_list]
ani = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)

HTML(ani.to_jshtml())

######################################################################
# **Real Images vs. Fake Images**

# Grab a batch of real images from the dataloader
real_batch = next(iter(dataloader))

# Plot the real images
plt.figure(figsize=(15, 15))
plt.subplot(1, 2, 1)
plt.axis("off")
plt.title("Real Images")
plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=5, normalize=True).cpu(), (1, 2, 0)))

# Plot the fake images from the last epoch
plt.subplot(1, 2, 2)
plt.axis("off")
plt.title("Fake Images")
plt.imshow(np.transpose(img_list[-1], (1, 2, 0)))
plt.show()
